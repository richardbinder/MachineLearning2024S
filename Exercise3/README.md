## Project Structure

The project is organized as follows:

- **`maps/`**: Contains the maps used in the project and the code to load and run them in a simulation.
    - **`map_*`**: Each map has its own folder containing a script to generate the map and a picture of the map (generated by the script). For a better understanding, refer to the `map_a` directory. All maps are saved in the `saved_tracks` folder as `.npy` files.
    - **`saved_tracks/`**: Contains the saved maps in `.npy` format.
    - **`game_environment.py`**: Contains the environment class used to run the simulation. For verification purposes, you can run the environment with random actions using the command `python game_environment.py`. To change the map, update the `track` parameter to the desired map:
    
    ```python
        # Example of how to run the environment with map a
        race_track = RaceTrack(track_dir='./saved_tracks/', track='a', size=20)

        # Example of how to run the environment with map b
        race_track = RaceTrack(track_dir='./saved_tracks/', track='b', size=20)

        # Example of how to run the environment with map c
        race_track = RaceTrack(track_dir='./saved_tracks/', track='c', size=20)
    ```

- **`policies/`**:
    - **`soft_behavior_policy.py`**: Contains the `soft_policy` function, which defines a soft behavior policy for the agents in the simulation.
    - **`off_policy_montecarlo.py`**: Implements the off-policy Monte Carlo control algorithm used for training the agents.
    - **`on_policy_montecarlo.py`**: Implements the on-policy Monte Carlo control algorithm used for training the agents.

- **`results/`**: Directory intended to store the results of the off policy simulations, such as reward histories and policy evaluations.
- **`results/`**: Directory intended to store the results of the on policy simulations, such as reward histories and policy evaluations.

- **`main.py`**: The main script for training and evaluating the policies. This script handles the overall flow of the project, including training the policies and generating evaluation plots.

## Running `main.py`

You can run `main.py` using the following command-line arguments to control its behavior:

- `--train`: Train the model (set to `True` to train the model and generate the Q matrix).
- `--plot`: Plot the results (set to `True` to generate plots for each initial state).
- `--sim`: Run simulations in the environment.
- `--track`: Specify the track name (`a`, `b`, or `c`).

### Example Commands

1. **Train the model on track `a`:**

    ```sh
    python main.py --train --track a
    ```

2. **Plot and run simulations for track `b`:**

    ```sh
    python main.py --plot --sim --track b
    ```

**Note**: In case you plot and run simulations at the same time, the script will first show the plots and after closing that windows the simulations will start.

3. **Training, plotting and running simulations on track `c`:**

    ```sh
    python main.py --train --plot --sim --track c
    ```
